{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully.\n",
      "OpenAI client configured for Qwen.\n",
      "\n",
      "Sending a test message to the Qwen model...\n",
      "\n",
      "✅ Success! Model responded:\n",
      "-> The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- 1. Load Environment Variables ---\n",
    "# This line loads the variables from your .env file\n",
    "load_dotenv() \n",
    "\n",
    "# --- 2. Retrieve the API Key ---\n",
    "# We get the API key from the environment variables.\n",
    "# It's crucial that the variable name here matches the one in your .env file.\n",
    "qwen_api_key = os.getenv(\"QWEN_API_KEY\")\n",
    "\n",
    "# --- 3. Check if the API Key was Found ---\n",
    "if not qwen_api_key:\n",
    "    # If the key is not found, we raise an error to stop execution.\n",
    "    # This is a common failure point, so we check it explicitly.\n",
    "    raise ValueError(\"QWEN_API_KEY not found in .env file. Please check your setup.\")\n",
    "\n",
    "print(\"API Key loaded successfully.\")\n",
    "\n",
    "# --- 4. Instantiate the OpenAI Client for Qwen ---\n",
    "# This is the key step for compatibility.\n",
    "# We point the OpenAI client to the Alibaba Cloud Dashscope endpoint.\n",
    "client = OpenAI(\n",
    "    api_key=qwen_api_key,\n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\" # This is the specific endpoint for Qwen\n",
    ")\n",
    "\n",
    "print(\"OpenAI client configured for Qwen.\")\n",
    "\n",
    "# --- 5. Make the API Call ---\n",
    "# We'll use a try...except block to gracefully handle any potential API errors.\n",
    "try:\n",
    "    print(\"\\nSending a test message to the Qwen model...\")\n",
    "\n",
    "    \n",
    "    # We create a simple chat completion request.\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-max\", # Using the powerful qwen-max model as planned\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # --- 6. Print the Response ---\n",
    "    # We access the content of the model's message from the response object.\n",
    "    model_response = response.choices[0].message.content\n",
    "    print(\"\\n✅ Success! Model responded:\")\n",
    "    print(f\"-> {model_response}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # If anything goes wrong during the API call, we print the error.\n",
    "    print(f\"\\n❌ An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
